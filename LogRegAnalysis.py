# -*- coding: utf-8 -*-
"""
Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SOqKdcR25pw-yyT79g2hX7vTmxfRvzdC

Import important libraries for splitting the training and testing data, to run the logistic regression model, and to evaluate results for accuracy and a confusion matrix
"""

import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve

"""Import and Process Data

- try without has_instagram and has_twitter
"""

import pandas as pd

# Load your dataset
df = pd.read_csv("dropped_leads.csv")

# Add binary column for high insta ratio
insta_mean = df['insta_ratio'].mean()
df['insta_ratio_high'] = (df['insta_ratio'] >= insta_mean).astype(int)

# List of columns to dummy encode
columns_to_dummy = ['LF-Industry', 'Lead Source Category','Referring_Bank_Region']

# Dummy encode them with 0 and 1 (NOT True/False)
df_dummies = pd.get_dummies(df[columns_to_dummy], prefix=columns_to_dummy, drop_first=True, dtype=int)

# Drop the original categorical columns
df = df.drop(columns=columns_to_dummy)

# Concatenate the dummy columns back into df
df_encoded = pd.concat([df, df_dummies], axis=1)

# Now, drop the extra columns you don't want (while keeping the dummies)
columns_to_drop = ["Lead and Referral ID", "Company_Name", "Facebook_URL", "Instagram_URL",
                   "insta_username", "insta_ratio", "twt_presence", "twt_ratio", "twt_handle", "Lead Source Channel"]

df_encoded = df_encoded.drop(columns=columns_to_drop, errors='ignore')


# Now df_encoded is ready: dummy variables are 0/1, and unwanted columns removed

df_encoded

"""The model will learn from the features in the data (X) and try to predict the target variable (y), it will measure the relationship between the features and the target

- Do one without Create_to_Oppt_Interval and Oppt_to_Sub_Interval
- Maybe do one with each?
"""

#top 10 features from your RF model
top_10_feature_names = ['LF-Industry_Restaurants & Quick Serve Restaurants', 'Lead Source Category_Self-sourced', 
                        'LF-Industry_Retail', 'Lead Source Category_Other', 'has_sum', 'Marketing_Campaign_Indicator', 
                        'LF-Industry_Professional Services', 'Engagement Score', 'LF-Industry_Health Care & Pharmacies', 
                        'insta_ratio_high']

X = df_encoded[top_10_feature_names]
y = df_encoded['Converted']


X = X.dropna()
y = y.loc[X.index]

# X = df_encoded.drop(columns=['Converted'])
# y = df_encoded['Converted']

"""Split the data- 80% training and 20% testing"""

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state= 42)

scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

model = LogisticRegression(class_weight= 'balanced', random_state=42) #tried class_weight= 'balanced' which decreased false and true negatives but increased everything else
model.fit(X_train_scaled,y_train)

y_pred = model.predict(X_test_scaled)
y_pred_proba = model.predict_proba(X_test_scaled)[:, 1] #probability of the positive class

accuracy = accuracy_score(y_test,y_pred)
print(accuracy)

coefficients = model.coef_[0]
feature_importance = pd.DataFrame({'Feature': X.columns, 'Coefficient': coefficients})
feature_importance = feature_importance.sort_values(by='Coefficient', ascending=False)
print(feature_importance)

"""- It is predicting correcty predicted Not Converted the most bc 48,765 companies are not converted and 14,267 are converted
- 857 True Negatives (correctly predicted Not Converted)
- 51 False Positives (wrongly predicted Conversions)
- 150 False Negatives (missed Conversions)
- 73 True Positives (correctly predicted Converted)
"""

conf_matrix = confusion_matrix(y_test, y_pred)
print(conf_matrix)

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

roc_auc = roc_auc_score(y_test, y_pred_proba)
print("\nROC AUC Score:", roc_auc)

fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f"ROC Curve (AUC = {roc_auc:.2f})", color="blue")
plt.plot([0, 1], [0, 1], "k--", label="Random Guess")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend(loc="lower right")
plt.grid()
plt.show()

import matplotlib.pyplot as plt

# Get coefficients
coefficients = model.coef_[0]
feature_importance = pd.DataFrame({'Feature': X.columns, 'Coefficient': coefficients})

# Sort by absolute coefficient value (biggest impact first)
feature_importance = feature_importance.reindex(feature_importance['Coefficient'].abs().sort_values(ascending=False).index)

# Keep only the top 10 features
feature_importance_top10 = feature_importance.head(10)

# Plot
plt.figure(figsize=(10,6))
plt.barh(feature_importance_top10['Feature'], feature_importance_top10['Coefficient'], color='steelblue')
plt.xlabel('Coefficient Value')
plt.ylabel('Top 10 Features')
plt.title('Top 10 Feature Importances (Logistic Regression Coefficients)')
plt.gca().invert_yaxis()  # Invert so highest coefficient is at the top
plt.xticks(fontweight='bold')
plt.yticks(fontweight='bold')
plt.show()

import seaborn as sns
plt.figure(figsize=(6, 4))

sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', cbar=False,
            xticklabels=['Not Converted', 'Converted'], yticklabels=['Not Converted', 'Converted'],
            annot_kws={"size": 16, 'weight': 'bold'}, linewidths=1, linecolor='black')

plt.xlabel('Predicted', fontsize=12)
plt.ylabel('Actual', fontsize=12)
plt.title('Confusion Matrix', fontsize=14)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)

plt.show()

"""Logistic Regression with Cut Data (5/6/2025)

do a second analysis of the interval data- show the progression over # of days how the chances of conversation decrease
"""

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve

data = pd.read_csv("/content/dropped_leads.csv")
data

"""Adden's Logit"""

data['Referring_Bank_Region'] = data['Referring_Bank_Region'].replace("No Info", np.nan)
data = data.dropna(subset=['Converted'])
odata = data.copy()

columne = odata.select_dtypes(exclude=['number']).columns.tolist()

# Log Reg. Formulation
X = odata.drop("Converted",axis=1)
y = odata[["Converted"]]

dumX = pd.get_dummies(X, columns=columne, prefix=columne, drop_first=True)
dumX = dumX.replace({False: 0, True: 1}).fillna(0).infer_objects(copy=False)

X_train, X_test, y_train, y_test = train_test_split(dumX, y, test_size=0.2, random_state=42)

model = LogisticRegression()
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train.values.ravel())

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

coefficients = model.coef_[0]
feature_importance = pd.DataFrame({'Feature': dumX.columns, 'Weight': coefficients})
feature_importance = feature_importance.sort_values(by='Weight', ascending=False)

feat = feature_importance.head(10)

plt.figure(figsize=(10,6))
plt.barh(feat['Feature'], feat['Weight'], color='steelblue')
plt.xlabel('Coefficient Value')
plt.ylabel('Top 10 Features')
plt.title('Top 10 Feature Importances (Logistic Regression Coefficients)')
plt.gca().invert_yaxis()
plt.xticks(fontweight='bold')
plt.yticks(fontweight='bold')
plt.show()

import matplotlib.pyplot as plt
import pandas as pd

# Assuming `feat` is already defined as top 10 features
plt.figure(figsize=(12, 7))
bars = plt.barh(feat['Feature'].str.replace('LF-Industry_', '').str.replace('_', ' '),  # cleaner labels
                feat['Weight'],
                color='#4C72B0')

# Add data labels at the end of each bar
for bar in bars:
    plt.text(bar.get_width() + 0.05, bar.get_y() + bar.get_height()/2,
             f'{bar.get_width():.2f}', va='center', fontsize=10, fontweight='bold')

# Titles and labels
plt.xlabel('Importance Score (Logistic Regression)', fontsize=12, labelpad=10)
plt.ylabel('')
plt.title('Top Industries Predicting Our Outcome', fontsize=16, weight='bold')
plt.suptitle('Based on Logistic Regression Model Coefficients', fontsize=12, color='gray')

# Make Y-axis easier to read
plt.gca().invert_yaxis()
plt.xticks(fontsize=10)
plt.yticks(fontsize=11)

# Remove unnecessary spines
for spine in ['top', 'right']:
    plt.gca().spines[spine].set_visible(False)

plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Generate predictions (adjust based on your setup)
y_pred = model.predict(X_test)  # or whichever test set you're using
conf_matrix = confusion_matrix(y_test, y_pred)

# Plot the confusion matrix
plt.figure(figsize=(6, 4))

sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', cbar=False,
            xticklabels=['Not Converted', 'Converted'],
            yticklabels=['Not Converted', 'Converted'],
            annot_kws={"size": 16, 'weight': 'bold'}, linewidths=1, linecolor='black')

plt.xlabel('Predicted', fontsize=12)
plt.ylabel('Actual', fontsize=12)
plt.title('Confusion Matrix', fontsize=14)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)

plt.tight_layout()
plt.show()

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt

# Get predicted probabilities for the positive class
y_probs = model.predict_proba(X_test)[:, 1]

# Compute ROC curve and ROC AUC
fpr, tpr, thresholds = roc_curve(y_test, y_probs)
auc_score = roc_auc_score(y_test, y_probs)

# Plot ROC Curve
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='red', lw=2, label=f'ROC curve (AUC = {auc_score:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Guessing')

plt.xlabel('False Positive Rate', fontsize=12)
plt.ylabel('True Positive Rate', fontsize=12)
plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=14)
plt.legend(loc='lower right', fontsize=11)
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()

# Print AUC Score
print(f"AUC Score: {auc_score:.4f}")

import re
import matplotlib.pyplot as plt
import pandas as pd

# Create dictionary of feature importances by matching column names
columnd = odata.columns
dic = {f"{b}": [] for b in columnd}

for a in range(len(feature_importance)):
    for b in columnd:
        if re.search(b, feature_importance.iloc[a, 0]):
            dic[f"{b}"].append(feature_importance.iloc[a, 1])

# Compute average weight for each feature
averages = {
    key: sum(values) / len(values) if values else None
    for key, values in dic.items()
}
avg_df = pd.DataFrame(list(averages.items()), columns=["Feature", "Avg. Weights"]).sort_values(by='Avg. Weights', ascending=False)
avg_df = avg_df[avg_df['Feature'] != "Converted"]

# Plot all features with cleaner, more styled formatting
plt.figure(figsize=(12, 7))
bars = plt.barh(
    avg_df['Feature'].str.replace('LF-Industry_', '', regex=False).str.replace('_', ' ', regex=False),
    avg_df['Avg. Weights'],
    color='#4C72B0'
)

# Add text labels outside the bars (to the right)
for bar in bars:
    plt.text(bar.get_width() + 0.05, bar.get_y() + bar.get_height()/2,
             f'{bar.get_width():.2f}', va='center', fontsize=10, fontweight='bold')

# Set axis titles and labels
plt.xlabel('Importance Score (Logistic Regression)', fontsize=12, labelpad=10)
plt.ylabel('')
plt.title('Feature Importances in Predicting Our Outcome', fontsize=16, weight='bold')
plt.suptitle('Based on Logistic Regression Model Coefficients', fontsize=12, color='gray')

# Style plot
plt.gca().invert_yaxis()
plt.xticks(fontsize=10)
plt.yticks(fontsize=11)
for spine in ['top', 'right']:
    plt.gca().spines[spine].set_visible(False)
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

data.columns

import matplotlib.pyplot as plt
import pandas as pd

# Assuming you've already fitted your model and have dumX
coefficients = model.coef_[0]
feature_importance = pd.DataFrame({'Feature': dumX.columns, 'Weight': coefficients})

# Filter for Lead Source Category features
leadsource_features = feature_importance[feature_importance['Feature'].str.startswith('Lead Source Category_')]

# Sort by coefficient weight
leadsource_features = leadsource_features.sort_values(by='Weight', ascending=False)

# Create horizontal bar plot
plt.figure(figsize=(12, 7))
bars = plt.barh(
    leadsource_features['Feature'].str.replace('Lead Source Category_', '').str.replace('_', ' '),
    leadsource_features['Weight'],
    color='#4C72B0'
)

# Add value labels outside each bar
for bar in bars:
    plt.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height() / 2,
             f'{bar.get_width():.2f}', va='center', fontsize=10, fontweight='bold')

# Title and labels
plt.xlabel('Coefficient Value (Logistic Regression)', fontsize=12)
plt.ylabel('')
plt.title('Logistic Regression Coefficients by Lead Source Category', fontsize=16, weight='bold')
plt.suptitle('Based on Dummy-Coded Features for Lead Sources', fontsize=12, color='gray')

# Formatting
plt.gca().invert_yaxis()
plt.xticks(fontsize=10)
plt.yticks(fontsize=11)
for spine in ['top', 'right']:
    plt.gca().spines[spine].set_visible(False)
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()